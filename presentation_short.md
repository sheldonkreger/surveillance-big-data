# Presentation

Imagine, in the near future, the rise of a commercial-grade 3D printer, which is used by hundreds of corporations around the world to manufacture components for thousands of products. Engineers use digital blueprints to program these machines, and they can share or even sell the blueprints to other companies. In the wrong hands, blueprints could be created to create deadly weapons. This kind of problem will manifest in manufacturing, but also in cyberspace, robotics, biology, and nanotechnology. Unless standards are created today, there is a high chance that such power will end up being used to cause catastrophe.

We will begin this discussion by exploring the philisophical argument that science will inevitably create technologies which create existential risk. Second, we'll review examples of some of the most immediately emerging threats in this space, and argue that surveillance will be a critical line of defense. Third, we will point out today's current misuse of surveillance - we'll detail how private companies currently exploit their customers through surviellance and big data systems, actively manipulating people to purchase products or participate in other agendas through a process called *instrumentarianism*. Fourth, we will see how governmental surveillance is legally distinguished from these corporate endeavors, but that corporate data is invaluable for thwarting future threats. Finally, we will argue that both privacy protections and defensive capabilities will be vastly superior if we address these problems immediately, before a catastrophe unfolds.

## Vulnerable World Hypothesis

Oxford philosopher Nick Bostrom specializes in the ethics of near-future problems such as human enhancement, artificial intelligence, and existential risk. In a recent paper, he lays the philosophical groundwork to argue that the scientific method will inevitably lead to technologies which pose danger to the survival of humanity.

Imagine an urn filled with balls that are white, black, and various shades of grey. Each time an invention is brought to life, humanity reaches into the urn and draws a ball. The white balls represent technologies which are generally positive for humanity, while the black balls represent inventions which lead to extinction. And, of course, there are many grey balls which exhibit both positive and negative traits. Thankfully, most of the balls so far have been grey or white. Bostrom, however, believes that in the near future, we will be pulling some dark grey or even black balls, and without some kind of social framework to address them, this will result in a major catastrophe.

> Intuitively, the hypothesis is that there is some level of technology at which civilization almost certainly gets destroyed unless quite extraordinary and historically unprecedented degrees of preventive policing and/or global  governance are implemented. More precisely:
>>
> -VWH: If technological development continues then a set of capabilities will at some point be attained that make the devastation of civilization extremely likely, unless civilization sufficiently *exits* the semi-anarchic default condition. (pg 6)

The "semi-anarchic default conditions" are:

> - Limited capacity for preventive policing.
> - Limited capacity for global governance.
> - Diverse personal motivations (including harming others).

It is important to frame the conversation around surveillance, big data, and privacy from this perspective.

## Emerging Grey Orbs

In their book "The Future of Violence", Gabriella Blum (Harvard Law Professor) and Benjamin Wittes (Senior Fellow in Governance Studies at the Brookings Institution) outline 'technologies of empowerment' which will give individuals or small groups the capability to cause major catastrophes. These fall into four categories:

- Bioweapons
- Cyberspace
- Robotics
- Nanotechnology

## Real-world Example

We have already seen examples of individuals manufacturing weapons at home using 3D printers. Just last month, a 3D weapons case was convicted for the first time in the UK. Upon discovering the weapon, investigators viewed his internet browsing history to discover he had viewed instructional videos.

Thankfully, today's 3D guns do not pose unprecedented risks - and they actually look quite pathetic in comparison to what we can buy from a dealer. But the underlying process of downloading instructions and creating weapons at home is a clear example of one of Bostrom's gray orbs. These threats will develop rapidly in the near future.

## Corporate Enforcement

The question, of course, is how to best respond to this challenge. One may be tempted to place the responsibility on internet corporations to patrol forums and shut down illegal activity as it arises. This is the existing way of doing things, and as we can see, it leaves too much room for imperfect policing, contingent upon the desires and resources of the companies in question. They have also failed to retain security over sensitive data. And, the data required to end Bostrom's 'semi-anarchic state' will be extremely diverse and sensitive in nature - so much so, in fact, that many companies today try to actively avoid cooperation with law enforcement due to the way it affects their public reputation.

But, there are many other reasons why this will not work. My argument is that relying upon tech companies to enforce policies designed to prevent massive catastrophes is not only inneffective, but it is extremely dangerous. This is because such bohemoths have historically abused the data they collect on individuals in order to exploit them later on. Fundamentally, their goal is not the protection of the public good, but rather to perpetually create profits.

## Surveillance Capitalism

Shoshana Zuboff, one of Havard Business School's first tenured female professors, provides a impressive account of corporate leveraging of big data in her 2019 masterpiece *The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power*. Having spent more than a decade interviewing top data scientists, engineers, and exectuives at major tech companies, Zuboff has documented the emergence of an unprecedented form of power called *instrumentarianism*.

## Instrumentarianism

Referencing several public lectures, presentations, and articles from tech industry leaders, Zuboff clarifies a narrative in which Silicon Valley businesses are racing for a complete system of surveillance and analysis. Through a rapidly expanding network of sensors, companies collect behavioral data and make predictions about future behavior. This data is currently used primarily to target advertisements to the consumers who are most likely to buy a product, based on mathematical analysis of previous behaviors. This process Zuboff calls *the prediction imperative* and is paired with the *extraction imperative*, or the endless drive to amass behavioral data. And, of course, the unrestrained nature of capitalism means these imperatives have no boundaries, as long as they remain profitable.

## Economies of Action

We are familiar with these systems in our every day lives, when we visit specific web pages and later recieve advertisements about those topics. Zuboff's work reveals, however, that the agenda reaches far beyond targeted advertising, but toward behavioral modification in general. Today, these queues manifest as notifications, search results, emails, and commercials. However, Zuboff argues that the ambitions of the tech companies are expanding beyond commercial advertising, toward behavior conditioning in general.

## Beyond Advertising - Recent Publications

One controversial example of behavioral manipulation was detailed in a 2012 article in *Nature*, where Facebook engineers had manipulatad 61 million individual news feeds in the run-up to the 2010 congressional election. They found that giving users a way to easily share the fact that they voted and prompting them with photos of their friends who had voted had a significant impact on voter turnout.

There are more and more examples of these kinds of studies in this explosive domain of sociology. While it may seem far-fetched to think these companies can dictate our behavior, take a moment to think about the influence they already have over us. Have you ever chosen a restaurant based on Yelp reviews? Or maybe you found a doctor with a Google search? Have any of your friends met their partners through dating apps? Have you ever chosen a different route or completely changed your plans because of traffic alerts sent to your phone? 

We have been conditioned to these seemingly minor changes over a very short period of time, maybe 15 years. Individually, they seem benign, but cumulitavely it represents an unprecedented shift in power which Zuboff argues is on the same scale of the rise of Totalitarianism in the 1900s (but, thankfully, without the physical violence). Rather than being convinced to join a cause and fight a political battle, we are instead *radically indifferent*, responding to the convenient queues surrounding us and then submitting our behavioral data, in an endless cycle to concentrate power in ways never before seen.

## Convergence

On the one hand, we see the inevitable rise of *technologies of mass empowerment*, which will allow small groups or individual rogue actors to execute catastrophic attacks against large populations. On the other hand, we see the broadening power of corporations through the manipulation of individual behavior. This leaves us one final area to examine, which is the government's own surveillance activities, as well as their relationships with private industry.

## FISA 702

Under the Foreign Intelligence Surveillance Act (FISA), Section 702, government agencies are allowed to surveil any non-US citizens outside the country. Spying on adversaries is standard procedure in countries around the world, and the US has maintained this capability for many reasons and it remains largely uncontroversial. In contrast, surveillance targetting US citizens is extremely controversial because of fourth ammendment protections. This surprising double-standard has created logistical complications which are unthinkable in other countries in the world.

Spy agencies work with telecommunications companies to organize and fund special directives to facilitate these missions, which are supervised by a special Foriegn Intelligence Surveillance Court.

> While 702 is targeted and is used to collect only a tiny percentage of the world’s communications, it still does involve massive scale. About 100,000 persons are targeted per year. This yields a lot of information. In 2011, when the number of selectors was smaller than it is today, the government acquired 250 million Internet communications, in addition to telephone conversations. And much of this information relates to persons other than the targets. The Washington Post conservatively estimated that for each targeted person the communications of at least 9 other people are collected.
> By definition, when the government is collecting the communications of a target, it is collecting the communications of those on the other end of the communications.  Even when the government is targeting only non-citizens abroad, it is certain to collect communications to and from citizens and persons in this country -- persons not suspected of any wrongdoing and not suspected of communicating anything of intelligence value.
> . . . Searching the 702 repository means that the government is able to retrieve communications of a US person without a court order – communications that the government could not have targeted without a court order in the first place.

https://www.acslaw.org/expertforum/section-702-renewal-opportunities-lost-and-gained/
JIM DEMPSEY Executive Director, Berkeley Center for Law and Technology Jan 29,2018

Furthermore, if a domestic target is identified coincidentally while conducting foriegn surveillance, this justifies a warrant to target that individual for further investigation.

Due to the complexity and senstive nature of surveillance, many questions remain unresolved, with ammendments proposed to the FISA legislation as recenlty as June 2019.

Cooperation between government agencies and private corporations is more than that - it's actually a fundamental shift in defensive power from public to private sector. Surveillance aside, defensive capabilities of physical products must be built-in by the manufacturer. For example, anti-counterfiet technology in high-end laser printers isn't something that the FBI could externally impose upon potential criminals - it has to be part of the printer itself.

This raises a number of significant questions:

1. What justifies the disparity in authority between government agencies - who seek to protect us - and private corporations - who seek to exploit us?
2. Given the frequency and scale of corporate database compromises, is it wise to trust them with securing this sensitive data, rather than allowing the government to handle it on their own?
3. With more communications happening within corporate platforms - such as Facebook groups and What'sApp - should we trust these companies to set their own policies?
4. Can the intelligence community keep up with the growing variety of communications platforms through ad-hoc directives?


## Achieving Stabilization
As a philosopher, Bostrom explores all possible ways to counter an easy nukes scenario, listed here. However, he concludes that only preventitve policing and global governance are workable. Surveillance, of course, is the core technology for this kind of system.

With sufficient surveillance, one could:
> - prevent the dangerous information from spreading
> - restrict access to requisite materials, instruments, and infrastructure
> - deter potential evildoers by increasing the chance of their getting caught
> - be more cautious and do more risk assessment work
> - establish some kind of surveillance and enforcement mechanism that would make it possible to interdict attempts to carry out a destructive act

## Hybrid Countermeasures

I envision this as an expansion of both government capabilities and stronger coordination with private corporations.

- First, Manufacturers of grey and black orb technologies are regulated to limit the function within safe parameters.
- Second, Technologies with potential for abuse via modification or hacking are surgically recalled, tracked, and disabled.
- Third, Professionals who need grey orb technologies for their work agree to ongoing surveillance to prevent catastrophes.
- Last, If a widely available technology suddenly becomes threatening, widespread surveillance should be in place to respond immediately.

## Voluntary Surveillance 

Returning to our 3D printer example, imagine a large commercial device which is used by hunderds of corporations in thousands of manufacturing facilities. Assume that such a printer could be used to manufacture dangerous weapons. The manufacturer of this printer would register with a federal agency and maintain a list of all units and their locations, as well as a list of individuals who have permission to operate them. These people would have a security clearance or license, but also be subject to a very high level of surveillance to facilitate preventitive policing. In addition, safegaurds within the device would be in place to prevent the creation of dangerous items.

This kind of agreement is justified because such employees would voluntarily subject themselves to surveillance in exchange for the right to work with the specialized equipment. This would be a step in the right direction, but I must agree with Bostrom that such measures alone would be insuffecient.

## Involuntary Surveillance

The future will also present situations where the general populace has access to black ball technologies. Imagine a scientist discovers a way to manufacture a super-virus using widely available lab equipment, found in universities around the country. In this scenario, the state needs a way to quickly identify individuals who have expressed interest in developing the virus. This would require a pre-existing database of highly sensitive behavioral data to be queried at a moment's notice. Such a database might include communications like phone records and emails, web and search history, geolociation data, and social media data. Intelligence officials could query this database to find individuals who downloaded the instruction manual for creating the virus and therefore have some hope for containing an otherwise hopeless situation.

## Legal Standards or the State of Exception

This of course runs contrary to fourth ammendment standards. The database could very easily be abused for general-purpose law enforcement, or when Bostrom calls 'turn-key totalitarianism' where political dissendents are identified by a ruling power. As I pointed out earlier, much of this data is already collected and analyzed by private corporations for profiteering. Now that we can see the role of surveillance and big data technologies in preventing future catastrophes, I believe it is time for a careful re-evaluation of the cultural and legal constructions which present barriers to these future defense efforts.

Given the high probabilty of a black orb scenario, we may be facing these tough choices sooner than later. However, if we choose not to confront them head-on, we will end up with suspension of normal constitutional law. Jus as the PATRIOT act was passed after the attacks on September 11th, 2001, technologies of empowerment could force the government to declare a state of emergency. As Giorgio Agamben explores in his 2005 book *The State of Exception*, the abrupt suspension of the law in the face of a crisis often comes at the price of human rights violations - such as "enemy combatants" held in Guantanamo Bay. Furthermore, this condition has a tendency to become a prolonged state of being. There is often not a return to normalcy. Surveillance and intelligence operations pose a unique problem, because they are often implemented in secret.

The time to confront technologies of mass empowerment is now, before a catastrophe unfolds and leads us into a state of exception. Even if there is a greatly diminished level of privacy in the general sense, we have a better chance at establishing important - and sustainable - boundaries, and in the process gain a strategic advantage against these emerging threats.
