Nick Bostrom, "The Vulnerable World Hypothesis," Working Paper, v. 3.44 (2018), https://nickbostrom.com/papers/vulnerable.pdf

## Introduction

In this paper, Oxford philosopher Nick Bostrom makes three key arguments:

- In the near future, more people will have easier access to technologies which can cause catastrophic destruction.
- This vulnerable world can only be stabilized through a vast expansion of policing and global governance.
- We must evaluate the costs and risks of ubiquitous surveillance and/or a unified global order in context of the vulnerable world hypothesis.

To warrant the first argument, Bostrom posits "The Urn of Inventions." One can imagine an urn with varying colors of balls - white, grey, and black. Each time we create a new invention or make a new discovery, humanity reaches into the urn and draws out a ball. Whiter balls have a positive effect on society with few negative side effects. As they become darker grey, however, the positive effects are lessened, or the drawbacks are increased. Finally, we have the black balls, which represent inventions which - absent outside intervention -  cause catastrophic damage and the end of civilization.

Thankfully, the overall net impact of inventions has been overwhelmingly positive for humanity. We have drawn some dark grey balls, however, such as the nuclear bomb, anthrax, and the like. These technologies, however, have been restrained in their application, primarily because of the difficulty of developing them. No rogue individual or small sect can create a nuclear weapon. 

In the urn of inventions, however, it is inevitable that we will one day draw one or more black balls which are not only extremely dangerous, but also easy to build. Bostom calls these "easy nukes." If Szilard and Einstien had supsected that nuclear weapons would have been low effort to build, their options would have been very limited. They could have evangelized for a ban on studying nuclear physics. And, even if this was politically feasible, in practical reality, another nation would have made the discovery, or the secret would have gotten out.

## The Vulnerable World Hypothesis

After setting the stage, Bostrom shares his formal definition.

> Intuitively, the hypothesis is that there is some level of technology at which civilization almost certainly gets destroyed unless quite extraordinary and historically unprecedented degrees of preventive policing and/or global  governance are implemented. More precisely:
>>
> -VWH: If technological development continues then a set of capabilities will at some point be attained that make the devastation of civilization extremely likely, unless civilization sufficiently *exits* the semi-anarchic default condition. (pg 6)

The "semi-anarchic default conditions" are:

> - Limited capacity for preventive policing. States do not have sufficiently reliable means of real-time surveillance and interception to make it virtually impossible for any individual or small group within their territory to carry out illegal actions—particularly actions that are very strongly disfavored by >99% of the population.
> - Limited capacity for global governance. There is no reliable mechanism for solving global coordination problems and protecting global commons—particularly in high-stakes situations where vital national security interests are involved.
> - Diverse motivations. There is a wide and recognizably human distribution of motives represented by a large population of actors (at both the individual and state level)—in particular, there are many actors motivated, to a substantial degree, by perceived self-interest (e.g. money, power, status, comfort and convenience) and there are some actors (“the apocalyptic residual”) who would act in ways that destroy civilization even at high cost to themselves. (pg 7)

This leads us to the key concern: Do the risks of continuing in the semi-anarchic state outweigh the cost of the radical developments needed in order to impose a high level of surveillance and policing?

In order to approach this, we have to postulate how badly a black ball would harm society. Bostrom draws a hard line in the sand in regards to a potential "catastrophe" - a single event which immediately wipes out 15% or more of the earth's population, or >50% of global GDP. This definition, of course, is not something he would advocate, but is used for illustritave purposes when discussing the nuances of the hypothesis as the paper progresses.


