# The Vulnerable World Hypothesis
Nick Bostrom, "The Vulnerable World Hypothesis," Working Paper, v. 3.44 (2018), https://nickbostrom.com/papers/vulnerable.pdf

## Introduction

In this paper, Oxford philosopher Nick Bostrom makes three key arguments:

- In the near future, more people will have easier access to technologies which can cause catastrophic destruction.
- This vulnerable world can only be stabilized through a vast expansion of policing and global governance.
- We must evaluate the costs and risks of ubiquitous surveillance and/or a unified global order in context of the vulnerable world hypothesis.

To warrant the first argument, Bostrom posits "The Urn of Inventions." One can imagine an urn with varying colors of balls - white, grey, and black. Each time we create a new invention or make a new discovery, humanity reaches into the urn and draws out a ball. Whiter balls have a positive effect on society with few negative side effects. As they become darker grey, however, the positive effects are lessened, or the drawbacks are increased. Finally, we have the black balls, which represent inventions which - absent outside intervention -  cause catastrophic damage and the end of civilization.

Thankfully, the overall net impact of inventions has been overwhelmingly positive for humanity. We have drawn some dark grey balls, however, such as the nuclear bomb, anthrax, and the like. These technologies, however, have been restrained in their application, primarily because of the difficulty of developing them. No rogue individual or small sect can create a nuclear weapon. 

In the urn of inventions, however, it is inevitable that we will one day draw one or more black balls which are not only extremely dangerous, but also easy to build. Bostom calls these "easy nukes." If Szilard and Einstien had supsected that nuclear weapons would have been low effort to build, their options would have been very limited. They could have evangelized for a ban on studying nuclear physics. And, even if this was politically feasible, in practical reality, another nation would have made the discovery, or the secret would have gotten out.

## The Vulnerable World Hypothesis

After setting the stage, Bostrom shares his formal definition.

> Intuitively, the hypothesis is that there is some level of technology at which civilization almost certainly gets destroyed unless quite extraordinary and historically unprecedented degrees of preventive policing and/or global  governance are implemented. More precisely:
>>
> -VWH: If technological development continues then a set of capabilities will at some point be attained that make the devastation of civilization extremely likely, unless civilization sufficiently *exits* the semi-anarchic default condition. (pg 6)

The "semi-anarchic default conditions" are:

> - Limited capacity for preventive policing. States do not have sufficiently reliable means of real-time surveillance and interception to make it virtually impossible for any individual or small group within their territory to carry out illegal actions—particularly actions that are very strongly disfavored by >99% of the population.
> - Limited capacity for global governance. There is no reliable mechanism for solving global coordination problems and protecting global commons—particularly in high-stakes situations where vital national security interests are involved.
> - Diverse motivations. There is a wide and recognizably human distribution of motives represented by a large population of actors (at both the individual and state level)—in particular, there are many actors motivated, to a substantial degree, by perceived self-interest (e.g. money, power, status, comfort and convenience) and there are some actors (“the apocalyptic residual”) who would act in ways that destroy civilization even at high cost to themselves. (pg 7)

This leads us to the key concern: Do the risks of continuing in the semi-anarchic state outweigh the cost of the radical developments needed in order to impose a high level of surveillance and policing?

In order to approach this, we have to postulate how badly a black ball would harm society. Bostrom draws a hard line in the sand in regards to a potential "catastrophe" - a single event which immediately wipes out 15% or more of the earth's population, or >50% of global GDP. This definition, of course, is not something he would advocate, but is used for illustritave purposes when discussing the nuances of the hypothesis as the paper progresses.

Another key point is that Bostrom states he is not trying to determine if the VWH is true or not, but rather to explain it thoroughly. He does stipulate, however, that it would be difficult to convince him that it is *untrue.*

## Topology of Vulnerabilities

Bostrom outlines five kinds of vulnerabilities:

1. *Easy nukes* in which one or more technologies emerges in the semi-anarchic default condition, allowing any rogue actor to cause widespread destruction.
2. *Safe first strike* in which a state actor develops a technology which ensures dominance in a first-strike scenario, without threat of retaliation. For example, imagine nuclear weapons with no mutually-assured-destruction.
3. (Referred to simply as 2-a) in which powerful actors can produce devastating weapons, and have enough incentive to do so, even in the face of retaliation and other consequences.
4. *Worse global warming* in which individual actors are incentivized to contribute to a destruction scenario (yet do not face adequate and immediate negative consequences), and the collective damages lead to catastrophe. This could happen whether the threat is understood by the individuals or not.
5. *Surprising strangelets* in which a technology carries a hidden risk such that default outcome when it is discovered is inadvertent destruction. For example, if the first nuclear bomb test had ignited the atmosphere on fire.

## Achieving Stabilization

Having painted this bleak picture, Bostrom gives four possibilities for achieving 'stabilization:'
> 1. Restrict technological development.
> 2. Ensure that there does not exist a large population of actors representing a wide and recognizably human distribution of motives.
> 3. Establish extremely effective preventitive policing.
> 4. Establish effective global governance.

One variant of the first idea is to allow technological devleopment generally, but restrain developments which are potentially threatening. This, however, violates the random charactaristic of the *urn of discoveries* and drawing the balls. And, of course, it is extraordinarily difficult, and would likely have to be implemented alongside 3 or 4 above. Bostrom does say that this solution is worth attempting.

The second idea involves what Bostrom calls *preference modification* which sounds identical to Zuboff's term *economies of action*. The problem is that in a world of *easy nukes*, even one rogue actor (or relatively small group of them) can ruin things for everybody. The other problem, obviously, is that manipulating everybody in such a way to completely remove any desires for mass destruction would be both difficult and costly (from a moral perspective). Bostom believes that maybe a 5-10% reduction in existential risk might be possible through (what Zuboff calls) *instrumentarianism*.

Thankfully, it's reasonable to expect *easy nukes* style technologies to develop slowly, rather than quickly. Therefore:

> These considerations notwithstanding, preference modification could be helpful in scenarios in which the set of empowered actors is initially limited to some small definable subpopulation. Some black-ball technologies, when they first emerge from the urn, might be difficult to use and require specialized equipment. There could be a period of several years before such a technology has been perfected to the point where an average individual could master it. During
this early period, the set of empowered actors could be quite limited; for example, it might consist exclusively of individuals with bioscience expertise working in a particular type of lab. Closer screening of applicants to positions in such labs could then make a meaningful dent in the risk that a destructive individual gains access to the biotech black ball within the first few years of its emergence. And that reprieve may offer an opportunity to introduce other countermeasures to provide more lasting stabilization, in anticipation of the time when the technology gets easy enough to use that it diffuses to a wider population. 

## Some Specific Countermeasues and their Limitations

Because my focus is on surveillance, I have omitted Bostrom's discussion on destruction scenarios 2, 3, 4, and 5 (at least for the moment). We will see later, however, that surveillance is a core technology which empowers the possible stabilization methods above.

Aside from modifying preferences and altering scientific progress, one could:
> - prevent the dangerous information from spreading
> - restrict access to requisite materials, instruments, and infrastructure
> - deter potential evildoers by increasing the chance of their getting caught
> - be more cautious and do more risk assessment work
> - establish some kind of surveillance and enforcement mechanism that would make it possible to interdict attempts to carry out a destructive act

Bostrom warns that the first three are obviously infeasible, and the last two on their own - although perhaps workable - are insufficient on their own. Surveillance and preventitive policing would theoretically avoid an 'easy nukes' scenario, but it would not deter a 'safe first strike.'

Another important aspect is that the effectiveness of preventitive policing will be determined not only by the advancement of the field, but by how rapidly and widespread 'easy nukes' become. If, for example, there was suddenly a way to build a catastrophic weapon using common materials which are already widely in circulation, it would be impossible counteract.

Having narrowed down the ineffective countermeasures, Bostrom settles on preventitive policing combined with strong global governance as the most promising approach. He briefly mentions that these options come with very serious downsides, but chooses not to discuss them because they are already widely discussed. He avoids an 'all things considered' analysis in favor of continuing the thought experiment.

## Preventitive Policing

This section of the paper paints a picture for some vague possibilities of preventitive policing. It is important to note this is not a recommendation, but a conceptual exploration to inspire further thought.

### High-Tech Panopticon

Jeremy Bentham's panopticon was first implemented in Britain in 1821. This system relied on the *illusion* of continouous surveillance to assure prisoners were abiding by the rules. In contrast, Bostrom conceptualizes a *freedom tag* which is a surveillance device worn by all citizens, at all times. Unlike a simple ankle monitor used for probation today, the freedom tag collects as much data as possible (geolocation, audio, visual, etc.) and delivers it to a centralized big data platform for real time analysis. Lawbreakers are identified in real time, and police respond to incidents as they arise.

Due to recent technological advancements resulting in price decreases, such a system may well be feasible, at least economically. For example, if the annual cost was $140 USD per person or below, it would represent less than 1% of global GDP. Another potential benefit is that the technology could be used to improve law enforcement in general, and may result in a net savings. There may be positive social side effects, as well:

>  If the system works as advertised, many forms of crime could be nearly eliminated, with concomitant reductions in costs of policing, courts, prisons, and other security systems. It might also generate growth in many beneficial cultural practices that are currently inhibited by a lack of social trust.

Bostrom also points out that the current trend in the commercial world is establishing widespread surveillance anyway - so:

> . . . Eventually something close to full surveillance becomes a reality—close enough that with just one more turn of the screw it can be turned into High-tech Panopticon.

This, of course, one of Zuboff's most deeply seated fears for the future.

The political feasibility, of course, is more challenging than the technical. There may be a way to incentivize individuals to willingly participate in Zuboff's *extraction imperative.* Or, a catastrophic event could occur which radically changes the public's perspective on the importance of privacy in context of black ball threats.

## Global Governance

'Worse global warming' and 'safe first strike' scenarios cannot be addressed by individual state actors. This is why Bostrom argues that both preventitive policing and global governance will be required to address future threats.

## Discussion / Conclusion (The Threat of Totalitarianism)

In the final sections, Bostrom briefly raises some of the concerns for a perfect policing and global governance system, and comes up with some responses. It is clear that although he's dodged this problem - and also has avoided answering if the Vulnerable World Hypothesis is even true in the first place - this section is written as though it is true.

The primary problem here is that even if such an all-encompassing surveillance and enforcement system were created with high standards for individual autonomy, it would regardless be a threat for totalitarian abuses with relatively minor modifications. Bostrom calls this "*turnkey totalitarianism.* He briefly mentions some countermeasures:

> One could try to reduce this risk by designing the system with appropriate technical and institutional safeguards. For example, one could aim for a system of “structured transparency” that prevents concentrations of power by organizing the information architecture so that multiple independent stakeholders must give their permission in order for the system to operate, and so that only the  pecific information that is legitimately needed by some decision-maker is made available to her, with suitable redactions and anonymization applied as the purpose permits. With some creative mechanism design, some machine learning, and some fancy cryptographic footwork, there might be no fundamental barrier to achieving a surveillance system that is at once highly effective at its official function yet also somewhat resistant to being subverted to alternative uses.

These ideas are vague at best - as is most of the discussion of technology and policy in this paper.

Bostrom gives some final thoughts and a list of polic recommendations. He believes that the risks of a surveillance state and global order turning into a totalitarian regime are very real, but they are outweighed by the urgency of the inevitable black ball technologies which will emerge in the near future. He argues that beginning this process early will give us a better chance at mitigating the negative consequences of a police state and protecting individual free agency. If we wait for a black ball to emerge, it could be devastating, and the response would be even more consequential in terms of totalitarianism.